{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de un Modelo de spaCy para Detección de Entidades Nombradas (NER)\n",
    "---\n",
    "Este notebook tiene como objetivo entrenar un modelo de procesamiento de lenguaje natural (NLP) utilizando la biblioteca spaCy para realizar tareas de detección de entidades nombradas (NER, por sus siglas en inglés).\n",
    "\n",
    "La detección de entidades nombradas es una técnica clave en NLP que permite identificar y clasificar entidades específicas en un texto, como nombres de personas, organizaciones, ubicaciones, fechas, cantidades, entre otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos del Notebook\n",
    "\n",
    "1. **Preparar los datos de entrenamiento**: Generar un conjunto de datos etiquetados para el entrenamiento del modelo.\n",
    "2. **Configurar el modelo**: Definir los parámetros del modelo y configurar spaCy para trabajar con datos personalizados.\n",
    "3. **Entrenar el modelo**: Utilizar los datos para ajustar el modelo de spaCy y mejorar su capacidad para detectar las entidades deseadas.\n",
    "4. **Evaluar el modelo**: Validar el rendimiento del modelo utilizando métricas como precisión, exhaustividad y F1.\n",
    "5. **Guardar y reutilizar el modelo**: Exportar el modelo entrenado para integrarlo en otras aplicaciones.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "\n",
    "import random\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training.example import Example\n",
    "from pathlib import Path\n",
    "from ast import literal_eval\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "from spacy.scorer import Scorer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Obtener ejemplos de calles\n",
    "\n",
    "Para crear nuestro set de entrenamiento, utilizaremos las calles de la ciudad de Madrid. Así, crearemos ejemplos con nombres reales que más tarde ayudarán a generalizar al modelo.\n",
    "\n",
    "Descargamos los datos del callejero de Madrid desde [aquí](https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=b3c41f3cf6a6c410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_callejero = pd.read_csv('../data/VialesVigentes_20241226.csv', sep = ';', encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cargados los datos, los visualizamos para entender con qué información estamos trabajando. Nos encontramos con 15 columnas, de las cuales solo nos interesan 3: VIA_CLASE, VIA_PAR y VIA_NOMBRE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COD_VIA</th>\n",
       "      <th>VIA_CLASE</th>\n",
       "      <th>VIA_PAR</th>\n",
       "      <th>VIA_NOMBRE</th>\n",
       "      <th>VIA_NOMBRE_ACENTOS</th>\n",
       "      <th>COD_VIA_COMIENZA</th>\n",
       "      <th>CLASE_COMIENZA</th>\n",
       "      <th>PARTICULA_COMIENZA</th>\n",
       "      <th>NOMBRE_COMIENZA</th>\n",
       "      <th>NOMBRE_ACENTOS_COMIENZA</th>\n",
       "      <th>COD_VIA_TERMINA</th>\n",
       "      <th>CLASE_TERMINA</th>\n",
       "      <th>PARTICULA_TERMINA</th>\n",
       "      <th>NOMBRE_TERMINA</th>\n",
       "      <th>NOMBRE_ACENTOS_TERMINA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31001337</td>\n",
       "      <td>AUTOVÍA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-1</td>\n",
       "      <td>A-1</td>\n",
       "      <td>31001349</td>\n",
       "      <td>AUTOVÍA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M-30</td>\n",
       "      <td>M-30</td>\n",
       "      <td>99000003</td>\n",
       "      <td>LUGAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIMITE TERMINO MUNICIPAL</td>\n",
       "      <td>LÍMITE TÉRMINO MUNICIPAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31001336</td>\n",
       "      <td>AUTOVÍA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-2</td>\n",
       "      <td>A-2</td>\n",
       "      <td>310200</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>DE</td>\n",
       "      <td>FRANCISCO SILVELA</td>\n",
       "      <td>FRANCISCO SILVELA</td>\n",
       "      <td>99000003</td>\n",
       "      <td>LUGAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIMITE TERMINO MUNICIPAL</td>\n",
       "      <td>LÍMITE TÉRMINO MUNICIPAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31001342</td>\n",
       "      <td>AUTOVÍA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-3</td>\n",
       "      <td>A-3</td>\n",
       "      <td>480800</td>\n",
       "      <td>PLAZA</td>\n",
       "      <td>DE</td>\n",
       "      <td>MARIANO DE CAVIA</td>\n",
       "      <td>MARIANO DE CAVIA</td>\n",
       "      <td>99000003</td>\n",
       "      <td>LUGAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIMITE TERMINO MUNICIPAL</td>\n",
       "      <td>LÍMITE TÉRMINO MUNICIPAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31001334</td>\n",
       "      <td>AUTOVÍA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-4</td>\n",
       "      <td>A-4</td>\n",
       "      <td>31001349</td>\n",
       "      <td>AUTOVÍA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M-30</td>\n",
       "      <td>M-30</td>\n",
       "      <td>99000003</td>\n",
       "      <td>LUGAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIMITE TERMINO MUNICIPAL</td>\n",
       "      <td>LÍMITE TÉRMINO MUNICIPAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31001341</td>\n",
       "      <td>AUTOVÍA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A-42</td>\n",
       "      <td>A-42</td>\n",
       "      <td>468400</td>\n",
       "      <td>AVENIDA</td>\n",
       "      <td>DEL</td>\n",
       "      <td>MANZANARES</td>\n",
       "      <td>MANZANARES</td>\n",
       "      <td>99000003</td>\n",
       "      <td>LUGAR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LIMITE TERMINO MUNICIPAL</td>\n",
       "      <td>LÍMITE TÉRMINO MUNICIPAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    COD_VIA VIA_CLASE VIA_PAR VIA_NOMBRE VIA_NOMBRE_ACENTOS  COD_VIA_COMIENZA  \\\n",
       "0  31001337   AUTOVÍA     NaN        A-1                A-1          31001349   \n",
       "1  31001336   AUTOVÍA     NaN        A-2                A-2            310200   \n",
       "2  31001342   AUTOVÍA     NaN        A-3                A-3            480800   \n",
       "3  31001334   AUTOVÍA     NaN        A-4                A-4          31001349   \n",
       "4  31001341   AUTOVÍA     NaN       A-42               A-42            468400   \n",
       "\n",
       "  CLASE_COMIENZA PARTICULA_COMIENZA    NOMBRE_COMIENZA  \\\n",
       "0        AUTOVÍA                NaN               M-30   \n",
       "1          CALLE                 DE  FRANCISCO SILVELA   \n",
       "2          PLAZA                 DE   MARIANO DE CAVIA   \n",
       "3        AUTOVÍA                NaN               M-30   \n",
       "4        AVENIDA                DEL         MANZANARES   \n",
       "\n",
       "  NOMBRE_ACENTOS_COMIENZA  COD_VIA_TERMINA CLASE_TERMINA PARTICULA_TERMINA  \\\n",
       "0                    M-30         99000003         LUGAR               NaN   \n",
       "1       FRANCISCO SILVELA         99000003         LUGAR               NaN   \n",
       "2        MARIANO DE CAVIA         99000003         LUGAR               NaN   \n",
       "3                    M-30         99000003         LUGAR               NaN   \n",
       "4              MANZANARES         99000003         LUGAR               NaN   \n",
       "\n",
       "             NOMBRE_TERMINA    NOMBRE_ACENTOS_TERMINA  \n",
       "0  LIMITE TERMINO MUNICIPAL  LÍMITE TÉRMINO MUNICIPAL  \n",
       "1  LIMITE TERMINO MUNICIPAL  LÍMITE TÉRMINO MUNICIPAL  \n",
       "2  LIMITE TERMINO MUNICIPAL  LÍMITE TÉRMINO MUNICIPAL  \n",
       "3  LIMITE TERMINO MUNICIPAL  LÍMITE TÉRMINO MUNICIPAL  \n",
       "4  LIMITE TERMINO MUNICIPAL  LÍMITE TÉRMINO MUNICIPAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_callejero.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez seleccionadas las columnas de interés, crearemos una columna adicional que sea la concatenación de la partícula y el nombre de la vía, ya que no estamos interesados de que nuestro modelo detecte las partículas de forma distinta al nombre de la vía.\n",
    "\n",
    "Así mismo, eliminaremos los registros que contengan vacíos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_calles = df_callejero[df_callejero.VIA_CLASE != 'AUTOVÍA'][['VIA_CLASE', 'VIA_PAR', 'VIA_NOMBRE']]\n",
    "\n",
    "df_calles['NOMBRE_VIA'] = df_calles['VIA_PAR'] + ' ' + df_calles['VIA_NOMBRE']\n",
    "df_calles.drop(columns = ['VIA_PAR', 'VIA_NOMBRE'], inplace  = True)\n",
    "\n",
    "\n",
    "df_calles.rename(columns={'VIA_CLASE': 'TIPO_VIA'}, inplace = True)\n",
    "df_calles.dropna(inplace =  True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIPO_VIA</th>\n",
       "      <th>NOMBRE_VIA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>DEL ABAD JUAN CATALAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>DE LA ABADA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>DE LOS ABADES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>DE LA ABADESA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CALLE</td>\n",
       "      <td>DE ABALOS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TIPO_VIA             NOMBRE_VIA\n",
       "7     CALLE  DEL ABAD JUAN CATALAN\n",
       "8     CALLE            DE LA ABADA\n",
       "9     CALLE          DE LOS ABADES\n",
       "10    CALLE          DE LA ABADESA\n",
       "11    CALLE              DE ABALOS"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_calles.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Generar direcciones ficticias\n",
    "\n",
    "Para terminar de crear las direcciones ficticias, añadiremos más señas a las calles de Madrid. Para ello, de manera aleatoria, incluiremos información sobre el número y la combinación piso-letra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_datos_entrenamiento(df, n):\n",
    "    \"\"\"\n",
    "    Genera N líneas aleatorias a partir de un DataFrame base.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame base para seleccionar líneas.\n",
    "        n (int): Número de líneas aleatorias a generar.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame con N líneas aleatorias generadas.\n",
    "    \"\"\"\n",
    "    lineas = []\n",
    "    for _ in range(n):\n",
    "        # Seleccionar una línea aleatoria del DataFrame base\n",
    "        row = df.sample(1).copy()\n",
    "\n",
    "        # Agregar un número aleatorio\n",
    "        pre_numero = random.choice(['n*', 'nr', 'nº', '', 'n'])\n",
    "        numero = random.randint(1, 50)\n",
    "        post_numero = random.choice(['', '', '', ','])\n",
    "        row['NUMERO'] = f'{pre_numero}{numero}{post_numero}'\n",
    "\n",
    "        # Agregar combinación aleatoria de piso y letra\n",
    "        piso = random.randint(1, 10)\n",
    "        letra = random.choice(['A', 'B', 'C', 'D', 'IZDA', 'DCHA', 'CTRO'])\n",
    "        espacio = random.choice([' ', '*', 'º', '', '-'])\n",
    "        combinacion = f\"{piso}{espacio}{letra}\"\n",
    "        row['RESTO'] = combinacion\n",
    "\n",
    "        # Agregar la línea generada a la lista\n",
    "        lineas.append(row)\n",
    "\n",
    "    # Combinar todas las líneas en un nuevo DataFrame\n",
    "    return pd.concat(lineas, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = generar_datos_entrenamiento(df_calles, 7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Estructurar los datos para el modelo\n",
    "\n",
    "Una vez terminamos de generar las direcciones ficticias, daremos forma a nuestros datos para poder entrenar el modelo de spacy. Esta estructura es específica para la librería SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crear_entidades(row):\n",
    "    texto = row['texto']\n",
    "    entidades = []\n",
    "    start = 0\n",
    "    for col, label in zip(['TIPO_VIA', 'NOMBRE_VIA', 'NUMERO', 'RESTO'], ['TIPO_VIA', 'NOMBRE_VIA', 'NUMERO', 'RESTO']):\n",
    "        value = str(row[col])\n",
    "        start = texto.find(value, start)  # Buscar el índice inicial de la entidad\n",
    "        if start != -1:\n",
    "            end = start + len(value)  # Índice final de la entidad\n",
    "            entidades.append((start, end, label))\n",
    "            start = end  # Actualizar el inicio para evitar errores en textos repetidos\n",
    "    return (texto, {'entities': entidades})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['texto'] = train_set['TIPO_VIA'] + ' ' + train_set['NOMBRE_VIA'] + ' ' + train_set['NUMERO'].astype(str) + ' ' + train_set['RESTO']\n",
    "train_set['entidades'] = train_set.apply(crear_entidades, axis=1)\n",
    "\n",
    "lista = train_set['entidades'].to_list()\n",
    "\n",
    "train, test = train_test_split(lista, test_size=0.25, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CALLE DE LOS MARTIRES DE PARACUELLOS n44 3 D',\n",
       " {'entities': [(0, 5, 'TIPO_VIA'),\n",
       "   (6, 36, 'NOMBRE_VIA'),\n",
       "   (37, 40, 'NUMERO'),\n",
       "   (41, 44, 'RESTO')]})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configurar el modelo\n",
    "\n",
    "Para entrenar el modelo, primeramente necesitamos seleccionar qué componentes del pipeline del modelo pre-configurado queremos modificar con nuestros datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "ner = nlp.get_pipe('ner')\n",
    "\n",
    "for _,annotations in train:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "pipe_exceptions = ['ner', 'trf_wordpiecer', 'trf_tok2vec']\n",
    "unaffected_pipe = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_iter = 50\n",
    "\n",
    "with nlp.disable_pipes(*unaffected_pipe):\n",
    "    for iteration in range(nr_iter):\n",
    "        random.shuffle(train)\n",
    "        losses = {}\n",
    "\n",
    "        batches = minibatch(train, size=8)\n",
    "        for batch in batches:\n",
    "            example = []\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example.append(Example.from_dict(doc, annotations))\n",
    "\n",
    "            nlp.update(example, drop = 0.3, losses=losses)\n",
    "\n",
    "        print(f\"Iteration {iteration} - Losses: {losses}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluar el modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities: [('PLAZA', 'TIPO_VIA'), ('DE ELÍPTICA', 'NOMBRE_VIA'), ('8,', 'NUMERO'), ('3*B', 'RESTO')]\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "test_text = \"PLAZA ELÍPTICA 8, 3*B\"\n",
    "doc = nlp(test_text)\n",
    "\n",
    "print(\"Entities:\", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_acc': 1.0,\n",
       " 'token_p': 1.0,\n",
       " 'token_r': 1.0,\n",
       " 'token_f': 1.0,\n",
       " 'sents_p': None,\n",
       " 'sents_r': None,\n",
       " 'sents_f': None,\n",
       " 'tag_acc': None,\n",
       " 'pos_acc': None,\n",
       " 'morph_acc': None,\n",
       " 'morph_micro_p': None,\n",
       " 'morph_micro_r': None,\n",
       " 'morph_micro_f': None,\n",
       " 'morph_per_feat': None,\n",
       " 'dep_uas': None,\n",
       " 'dep_las': None,\n",
       " 'dep_las_per_type': None,\n",
       " 'ents_p': 0.9966711051930759,\n",
       " 'ents_r': 0.998,\n",
       " 'ents_f': 0.9973351099267155,\n",
       " 'ents_per_type': {'TIPO_VIA': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       "  'NOMBRE_VIA': {'p': 0.9920212765957447,\n",
       "   'r': 0.9946666666666667,\n",
       "   'f': 0.9933422103861518},\n",
       "  'NUMERO': {'p': 0.9973404255319149, 'r': 1.0, 'f': 0.9986684420772304},\n",
       "  'RESTO': {'p': 0.9973333333333333,\n",
       "   'r': 0.9973333333333333,\n",
       "   'f': 0.9973333333333333}},\n",
       " 'cats_score': 0.0,\n",
       " 'cats_score_desc': 'macro F',\n",
       " 'cats_micro_p': 0.0,\n",
       " 'cats_micro_r': 0.0,\n",
       " 'cats_micro_f': 0.0,\n",
       " 'cats_macro_p': 0.0,\n",
       " 'cats_macro_r': 0.0,\n",
       " 'cats_macro_f': 0.0,\n",
       " 'cats_macro_auc': 0.0,\n",
       " 'cats_f_per_type': {},\n",
       " 'cats_auc_per_type': {}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = []\n",
    "scorer = Scorer()\n",
    "for text, annotations in test:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    example.predicted = nlp(str(example.predicted))\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TIPO_VIA': {'p': 1.0, 'r': 1.0, 'f': 1.0},\n",
       " 'NOMBRE_VIA': {'p': 0.9920212765957447,\n",
       "  'r': 0.9946666666666667,\n",
       "  'f': 0.9933422103861518},\n",
       " 'NUMERO': {'p': 0.9973404255319149, 'r': 1.0, 'f': 0.9986684420772304},\n",
       " 'RESTO': {'p': 0.9973333333333333,\n",
       "  'r': 0.9973333333333333,\n",
       "  'f': 0.9973333333333333}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scorer = scorer.score(examples)\n",
    "results_scorer['ents_per_type']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
